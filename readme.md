# 🎓 Workshop: Getting Started with Ollama & Running LLaMA Models

Welcome to our hands-on workshop! This guide walks you through installing **Ollama**, running **LLaMA models**, customizing behavior, and backing up results — all beginner-friendly!

---

## 👨‍💻 Presenters

**Muneer – Tech Guide**  
AI educator & open-source advocate. Focused on simplifying complex tools.

**Aishwarya – Clarity Coach**  
Software engineer committed to making AI learning easy and fun.

---

## 🧭 Table of Contents

1. [What is Ollama?](#what-is-ollama)
2. [Why Use Ollama?](#why-use-ollama)
3. [What You’ll Need](#what-youll-need)
4. [Installing Ollama](#installing-ollama)
5. [Running LLaMA Models](#running-llama-models)
6. [Customizing Model Behavior](#customizing-model-behavior)
7. [Understanding Responses](#understanding-responses)
8. [Backing Up Outputs to Google Drive](#backing-up-outputs-to-google-drive)
9. [Troubleshooting](#troubleshooting)
10. [Contributing to Ollama](#contributing-to-ollama)
11. [License](#license)
12. [Contact](#contact)
13. [Appendix: Full Install Script](#appendix-full-install-script)

---

## 🧠 What is Ollama?

**Ollama** is an open-source tool that lets you run LLMs (like LLaMA3) locally — no internet required post-setup.

- 🔐 Private by default  
- ⚡ Fast & efficient  
- 🧠 Supports popular models  
- 🖥️ Works on macOS, Linux & Windows (WSL)

---

## 💡 Why Use Ollama?

| Feature             | Benefit                                    |
|--------------------|---------------------------------------------|
| ✅ Runs Locally     | Full offline capabilities after download    |
| 🔐 Private          | No data leaves your device                  |
| 🚀 Simple Setup     | Works across platforms                      |
| 🧠 Model Variety    | LLaMA, Mistral, and more supported           |
| 🔄 Dev Friendly     | Python integration and automation ready     |

---

## 🧰 What You’ll Need

- 💻 macOS / Linux / Windows (WSL2)
- 💾 Minimum 8GB RAM (16GB+ recommended)
- 🌐 Internet for downloading models
- 🧑‍💻 Basic Terminal skills

---

## ⚙️ Installing Ollama

### macOS
```bash
curl -fsSL https://ollama.com/install.sh | sh
